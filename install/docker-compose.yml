services:
  my_base_service:
    container_name: base_service
    user: "${GID:-1000}:${UID:-1000}"
    working_dir: /usr/src/app
    build:
      context: .
      args:
        - "UID=${UID:-1000}"
        - "GID=${GID:-1000}"
        - "MYUSER=${MYUSER:-container_user}"
    env_file:
      - ".env"

  quarto:
    extends:
      service: my_base_service
    container_name: quarto-container
    build:
      dockerfile: ./Dockerfiles/Dockerfile.quarto
    command: quarto render slides.qmd --to revealjs
    # command: bash
    # tty: true

  my_nvim:
    extends:
      service: my_base_service
    container_name: neodock
    hostname: neodock
    build:
      dockerfile: ./Dockerfiles/Dockerfile.editor
    command: /bin/bash && config submodule init && config submodule update
    tty: true

  julia:
    extends:
      service: my_base_service
    container_name: julia-1-9-3_morph
    build:
      dockerfile: ./Dockerfiles/Dockerfile.julia
    extra_hosts:
      - "python-3-10:127.0.0.1"
    environment:
      - CONFIG_FILE_PATH=configs/dashboard_config_disk.json
    network_mode: host
    command: julia Dashboard_App.jl

  python:
    extends:
      service: my_base_service
    container_name: repo-setter-python
    build:
      dockerfile: ./Dockerfiles/Dockerfile.python
    environment:
      - DISPLAY=$DISPLAY
    command: python3 dashboard.py
    privileged: true # To avoid libGL errors
    network_mode: host

  latex:
    extends:
      service: my_base_service
    container_name: latex
    build:
      dockerfile: ./Dockerfiles/Dockerfile.latex
    command: make
    # tty: true # makes the container running even when the command is finished.

  node_js:
    extends:
      service: my_base_service
    container_name: node_js
    build:
      context: .. # to add demos in build context
      dockerfile: ./install/Dockerfiles/Dockerfile.node_js
    command: npm start
    network_mode: bridge
    ports:
      - 7346:7346
      - 35729:35729

  # test python instructor with requests + torch with fastAPI to make the computations
  python_torch:
    extends:
      service: my_base_service
    container_name: python_torch_repo-setter
    build:
      context: .
      dockerfile: ./Dockerfiles/Dockerfile.python
    environment:
      - DISPLAY=$DISPLAY
    command: python3 torch_instructions.py
    depends_on:
      - torch
    network_mode: host
    extra_hosts:
      - "torch_repo-setter:127.0.0.1"

  torch:
    extends:
      service: my_base_service
    container_name: torch_repo-setter
    build:
      context: .
      dockerfile: ./Dockerfiles/Dockerfile.pytorch
    environment:
      - DISPLAY=$DISPLAY
    # this command makes the container never stop
    # useful for navigating in it with docker exec
    #command: tail -f /dev/null
    #
    command: python3 torch_computations.py
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    network_mode: host
